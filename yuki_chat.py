from dotenv import load_dotenv
import os
import json
import unicodedata
from datetime import datetime
from ai_backends.openai_backend import OpenAIBackend # OpenAIç”¨ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰
from ai_backends.llama_backend import LlamaBackend 
from ai_backends.base import AIInterface  # â† å‹ã¨ã—ã¦ä½¿ã†ãªã‚‰OK
from interaction.self_talker import SelfTalker
from braina.router import route_context


from yuki_chat_threaded import run_chat
from utils.memory import (
    load_state,
    save_state,
    add_to_memory,
    summarize_state_to_long_memory,
    refine_user_profile,
)

from utils.episode_memory import (
    pic_episode_memory
)

#Yukiã¡ã‚ƒã‚“ã®æƒ…å ±ã®å‘¼ã³å‡ºã—
YUKI_PERSONALITY_PATH = os.path.join("Yuki_memory", "yuki_personality.json")

#useræƒ…å ±ã®å‘¼ã³å‡ºã—
USER_FIXED_PROFILE_PATH = os.path.join("user_memory", "user_fixed_profile.json")
USER_PROFILE_PATH = os.path.join("user_memory", "user_profile.json")

#ä¼šè©±ç”¨ã®jsonãƒ•ã‚¡ã‚¤ãƒ«ã®å‘¼ã³å‡ºã—
STATE_PATH = os.path.join("talk_memory", "state.json")
USER_MEMORY_PATH = os.path.join("talk_memory", "user_memory.json")


# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# OpenAIç”¨ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼ˆçµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼‰

api_key = os.getenv("OPENAI_API_KEY")
ai = OpenAIBackend(api_key=api_key, model="gpt-4o-mini")

# Llamaç”¨ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼ˆçµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼‰
#ai = LlamaBackend(model="llama3")

# é›ªã¡ã‚ƒã‚“ã®åŸºæœ¬äººæ ¼ï¼ˆå¤‰æ›´ã•ã‚Œãªã„ã®ã§æœ€åˆã«ä¸€åº¦ã ã‘èª­ã¿è¾¼ã‚€ï¼‰
with open(YUKI_PERSONALITY_PATH, "r", encoding="utf-8") as f:
    yuki_data = json.load(f)

#ãƒ¦ãƒ¼ã‚¶ã®å›ºå®šãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã®èª­ã¿è¾¼ã¿
with open(USER_FIXED_PROFILE_PATH, "r", encoding="utf-8") as f:
    user_fixed_profile = json.load(f)

#ã€€æ™‚é–“ã‚’æ¸¡ã™
def build_time_prompt():
    now = datetime.now()
    return f"ç¾åœ¨ã®æ—¥æ™‚ã¯ {now.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')} ã§ã™ã€‚"

def build_system_prompt():
    rules_text = " ".join(yuki_data["rules"].values())
    likes_text = "ãƒ»".join(yuki_data["likes"])
    examples = "\n".join(
        f"Q: {q}\nA: {a}"
        for q, a in yuki_data["xt"][:3]
    )
    return (
        f"ã‚ãªãŸã¯18æ­³ã®å°‘å¥³ã€Œ{yuki_data['name']}ã€ã¨ã—ã¦æŒ¯ã‚‹èˆã„ã¾ã™ã€‚"
        f"{yuki_data['appearance']}ã€‚\n"
        f"å£èª¿ã¯{yuki_data['speech_style']}ã€‚\n"
        f"{yuki_data['personality']}\n\n"
        f"### ä¼šè©±ä¾‹\n{examples}\n\n"
        f"### å¥½ããªã‚‚ã®\n{likes_text}\n\n"
        f"### è¨­å®š\n{yuki_data['setting']}\n\n"
        f"### ãƒ«ãƒ¼ãƒ«\n{rules_text}"
    ).strip()

def build_userfixed_profile():
    return f"""
ã€ãƒã‚¹ã‚¿ãƒ¼ãƒ»ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã€‘
â—† å‘¼ã³æ–¹.    : {user_fixed_profile['call']}
â—† ãŠèª•ç”Ÿæ—¥   : {user_fixed_profile['birthday']}
â—† è·æ¥­.     : {user_fixed_profile['occupation']}
â—† é›ªã¡ã‚ƒã‚“ã®æƒ³ã„: {user_fixed_profile['attitude']}
â—† æ‰€åœ¨åœ°    : {user_fixed_profile['location']}
""".strip()

def build_long_term_prompt():

    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„ or ç©ºãªã‚‰ç©ºã® dict ã‚’ä½¿ã†
    if not os.path.exists(USER_PROFILE_PATH) or os.path.getsize(USER_PROFILE_PATH) == 0:
        print("âš ï¸ user_profile.json ãŒç©ºã‹å­˜åœ¨ã—ã¾ã›ã‚“ã€‚ç©ºã®è¨˜æ†¶ã§é€²è¡Œã—ã¾ã™ã€‚")
        mem = {}
    else:
        with open(USER_PROFILE_PATH, "r", encoding="utf-8") as f:
            try:
                mem = json.load(f)
            except json.JSONDecodeError:
                print("âš ï¸ user_profile.json ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆå½¢å¼ãŒå£Šã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ï¼‰")
                mem = {}

    # ğŸ” long_memory.json ã«åŒæœŸã‚³ãƒ”ãƒ¼
    with open(USER_MEMORY_PATH, "w", encoding="utf-8") as f:
        json.dump(mem, f, ensure_ascii=False, indent=2)

    # è¡¨ç¤ºç”¨ã«æ•´å½¢
    lines = []

    for key, value in mem.items():
        if isinstance(value, list):
            if all(isinstance(v, dict) and "value" in v for v in value):
                joined = "ãƒ»".join(v["value"] for v in value)
            else:
                joined = "ãƒ»".join(map(str, value))
            lines.append(f"{key}ï¼š{joined}")
        elif isinstance(value, dict):
            sub_lines = [f"{key}ï¼š"]
            for sub_key, sub_value in value.items():
                sub_lines.append(f"  {sub_key}: {sub_value}")
            lines.extend(sub_lines)
        else:
            lines.append(f"{key}ï¼š{value}")

    return "ä»¥ä¸‹ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é–¢ã™ã‚‹é•·æœŸè¨˜æ†¶ã§ã™ï¼š\n" + "\n".join(lines)


#æ–‡å­—ã‚’åˆ¤æ–­
def normalize(text):
    return unicodedata.normalize("NFKC", text).lower()

exit_words = ["exit", "quit", "çµ‚ã‚ã‚Š", "çµ‚äº†", "ã°ã„ã°ã„", "ã¾ãŸã­", "ã•ã‚ˆãªã‚‰"]


def main():
    state = load_state()
    state.setdefault("memory", [])
    conversation_count = 0
    episode_memory_prompt = ""
    talker = run_chat(state)  # â† OKï¼


    
    try:
        while True:

            user_input = input("ã‚ãªãŸ: ")
            talker.reset_timer()

            result = route_context(user_input)

            if normalize(user_input) in map(normalize, exit_words):
                print("é›ª: ã¾ãŸè©±ãã†ã­ã€‚ãŠã¤ã‹ã‚Œã•ã¾ã£â™ª")
                break

            add_to_memory(state, "user", user_input)
            conversation_count += 1

            if conversation_count % 3 == 0:
                # 3ã‚¿ãƒ¼ãƒ³ã”ã¨ã«ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶ã‚’æŠ½å‡º
                episode_memory_prompt = pic_episode_memory()


            if conversation_count % 20 == 0:
                summarize_state_to_long_memory(state, ai)

            full_prompt = build_time_prompt() + "\n" + build_system_prompt() + "\n" + build_userfixed_profile() + "\n" + build_long_term_prompt() + "\n" + result + "\n" +episode_memory_prompt
            messages = [{"role": "system", "content": full_prompt}] + state["memory"][-10:]

            reply = ai.generate(messages)
            print("é›ª:", reply)

            add_to_memory(state, "assistant", reply)
            save_state(state)


    except KeyboardInterrupt:
        print("\né›ª: ã°ã„ã°ã„â€¦")

    finally:
        talker.stop()  # â˜…è¿½åŠ ï¼šã‚¿ã‚¤ãƒãƒ¼åœæ­¢ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰çµ‚äº†ï¼‰
        # çŸ­æœŸè¨˜æ†¶ã®ä¿å­˜ï¼ˆexitç›´å‰ã®å…¥åŠ›ã‚„å¿œç­”ï¼‰
        save_state(state)

        # é•·æœŸè¨˜æ†¶ã«è¦ç´„ã‚’åæ˜ 
        summarize_state_to_long_memory(state, ai)

        # é•·æœŸè¨˜æ†¶ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ user_profile ã«åæ˜ 
        refine_user_profile(ai)



if __name__ == "__main__":
    main()